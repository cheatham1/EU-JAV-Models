# EU-JAV-Models

xlm-roberta-large

epochs = 11

learning rate 2e-5 

warm up = 10% 

batch_size = 16

f1-score: 0.74
